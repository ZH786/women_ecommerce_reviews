{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Womens Clothing E-Commerce Reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 23486 entries, 0 to 23485\nData columns (total 11 columns):\n #   Column                   Non-Null Count  Dtype \n---  ------                   --------------  ----- \n 0   Unnamed: 0               23486 non-null  int64 \n 1   Clothing ID              23486 non-null  int64 \n 2   Age                      23486 non-null  int64 \n 3   Title                    19676 non-null  object\n 4   Review Text              22641 non-null  object\n 5   Rating                   23486 non-null  int64 \n 6   Recommended IND          23486 non-null  int64 \n 7   Positive Feedback Count  23486 non-null  int64 \n 8   Division Name            23472 non-null  object\n 9   Department Name          23472 non-null  object\n 10  Class Name               23472 non-null  object\ndtypes: int64(6), object(5)\nmemory usage: 2.0+ MB\n"
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[['Review Text','Recommended IND']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                         Review Text  Recommended IND\n0  Absolutely wonderful - silky and sexy and comf...                1\n1  Love this dress!  it's sooo pretty.  i happene...                1\n2  I had such high hopes for this dress and reall...                0\n3  I love, love, love this jumpsuit. it's fun, fl...                1\n4  This shirt is very flattering to all due to th...                1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Review Text</th>\n      <th>Recommended IND</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Absolutely wonderful - silky and sexy and comf...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I had such high hopes for this dress and reall...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>This shirt is very flattering to all due to th...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Review Text        845\nRecommended IND      0\ndtype: int64"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "df1.isnull().sum() #845 missing reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1    18540\n0     4101\nName: Recommended IND, dtype: int64"
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "df1['Recommended IND'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.dropna(inplace = True) #drop the missing reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[]"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "blanks = []\n",
    "for i, rv, lb in df1.itertuples():\n",
    "    if rv.isspace():\n",
    "        blanks.append(i)\n",
    "blanks\n",
    "# no blank spaces in our reviews so we can move on!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df1['Review Text']\n",
    "y = df1['Recommended IND']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<15848x12200 sparse matrix of type '<class 'numpy.int64'>'\n\twith 678966 stored elements in Compressed Sparse Row format>"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "count_vec = CountVectorizer()\n",
    "Xtrain_counts = count_vec.fit_transform(X_train)\n",
    "Xtrain_counts #14145 number of unique words in our corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tfidf_trans = TfidfTransformer()\n",
    "Xtrain_tfidf = tfidf_trans.fit_transform(Xtrain_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TfidfVectorizer does both CountVectorizer and TfidfTransformer in one function\n",
    "txt_clf = Pipeline([('tfidf',TfidfVectorizer()),('clf',LinearSVC())]) #Applying a basic SVC algorithm as a benchmark model to beat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Pipeline(memory=None,\n         steps=[('tfidf',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=True, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=None, use_idf=True,\n                                 vocabulary=None)),\n                ('clf',\n                 LinearSVC(C=1.0, class_weight=None, dual=True,\n                           fit_intercept=True, intercept_scaling=1,\n                           loss='squared_hinge', max_iter=1000,\n                           multi_class='ovr', penalty='l2', random_state=None,\n                           tol=0.0001, verbose=0))],\n         verbose=False)"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "txt_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = txt_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[ 778  469]\n [ 265 5281]]\n"
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "precision    recall  f1-score   support\n\n           0       0.75      0.62      0.68      1247\n           1       0.92      0.95      0.94      5546\n\n    accuracy                           0.89      6793\n   macro avg       0.83      0.79      0.81      6793\nweighted avg       0.89      0.89      0.89      6793\n\n"
    }
   ],
   "source": [
    "print(classification_report(y_test,ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}